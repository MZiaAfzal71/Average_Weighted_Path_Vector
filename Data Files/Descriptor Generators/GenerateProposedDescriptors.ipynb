{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNC5a2lddWXJrDxyaUp5vjQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MZiaAfzal71/Average_Weighted_Path_Vector/blob/main/Data%20Files/Descriptor%20Generators/GenerateProposedDescriptors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vY2B_vT8sJ3i"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/MZiaAfzal71/Average_Weighted_Path_Vector.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "id": "x3wXQcRbsikT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Average_Weighted_Path_Vector/Data\\ Files"
      ],
      "metadata": {
        "id": "qMBiFRoxu1cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdmolops\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from typing import Tuple\n",
        "import os"
      ],
      "metadata": {
        "id": "VMUQfHuVsqwK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mol_from_smile(sm : str) -> Chem.Mol:\n",
        "      try:\n",
        "        mol = Chem.MolFromSmiles(sm)  # Convert SMILES to RDKit Mol\n",
        "        return mol\n",
        "      except:\n",
        "        return None\n",
        "\n",
        "def count_atom_types(mol : Chem.Mol) -> dict[str, int]:\n",
        "    atom_counts = defaultdict(int)\n",
        "    for atom in mol.GetAtoms():\n",
        "        atom_symbol = atom.GetSymbol()\n",
        "        atom_counts[atom_symbol] += 1\n",
        "\n",
        "    return dict(atom_counts)\n",
        "\n",
        "\n",
        "def mol_to_nx_graph(mol : Chem.Mol) -> nx.Graph:\n",
        "    \"\"\"Convert RDKit molecule to NetworkX graph with bond weights.\"\"\"\n",
        "    G = nx.Graph()\n",
        "    for bond in mol.GetBonds():\n",
        "        i = bond.GetBeginAtomIdx()\n",
        "        j = bond.GetEndAtomIdx()\n",
        "        weight = bond.GetBondTypeAsDouble()\n",
        "        G.add_edge(i, j, weight=weight)\n",
        "    return G\n",
        "\n",
        "\n",
        "def get_max_distance_atom_pairs(mol : Chem.Mol) -> Tuple[int, np.ndarray]:\n",
        "    \"\"\"Get atom index pairs with the maximum topological distance.\"\"\"\n",
        "    dmat = rdmolops.GetDistanceMatrix(mol)\n",
        "    max_dist = int(np.max(dmat))\n",
        "    max_indices = np.argwhere(dmat == max_dist)\n",
        "    return max_dist, max_indices\n",
        "\n",
        "\n",
        "def compute_avg_weighted_path_vector(mol : Chem.Mol) -> np.ndarray:\n",
        "    \"\"\"Main function to compute averaged weighted path vector descriptor.\"\"\"\n",
        "    G = mol_to_nx_graph(mol)\n",
        "    max_dist, max_pairs = get_max_distance_atom_pairs(mol)\n",
        "\n",
        "    if max_pairs.size == 0:\n",
        "        return []\n",
        "\n",
        "    # Get unique atoms involved in the longest paths\n",
        "    max_dist_atoms = set(max_pairs.flatten())\n",
        "    path_vectors = []\n",
        "\n",
        "    for start_atom in max_dist_atoms:\n",
        "        len_to_total_weight = defaultdict(float)\n",
        "\n",
        "        try:\n",
        "            lengths = dict(nx.single_source_shortest_path_length(G, start_atom))\n",
        "        except nx.NodeNotFound:\n",
        "            continue  # atom not in graph\n",
        "\n",
        "        for end_atom, path_len in lengths.items():\n",
        "            if start_atom == end_atom or path_len == 0:\n",
        "                continue\n",
        "            try:\n",
        "                paths = nx.all_shortest_paths(G, source=start_atom, target=end_atom)\n",
        "                for path in paths:\n",
        "                    total_weight = 0.0\n",
        "                    for i in range(len(path) - 1):\n",
        "                        bond_data = G.get_edge_data(path[i], path[i + 1])\n",
        "                        if bond_data:\n",
        "                            total_weight += bond_data['weight']\n",
        "                    len_to_total_weight[path_len] += total_weight\n",
        "            except (nx.NetworkXNoPath, nx.NodeNotFound):\n",
        "                continue\n",
        "\n",
        "        if not len_to_total_weight:\n",
        "            continue\n",
        "\n",
        "        max_len = max(len_to_total_weight.keys())\n",
        "        vector = [len_to_total_weight.get(i, 0.0) for i in range(1, max_len + 1)]\n",
        "        path_vectors.append(vector)\n",
        "\n",
        "    # Handle varying vector lengths by padding with zeros\n",
        "    if not path_vectors:\n",
        "        return []\n",
        "\n",
        "    max_vector_len = max(len(vec) for vec in path_vectors)\n",
        "    padded_vectors = [\n",
        "        vec + [0.0] * (max_vector_len - len(vec)) for vec in path_vectors\n",
        "    ]\n",
        "\n",
        "    # Average across all start atoms\n",
        "    avg_vector = np.mean(padded_vectors, axis=0).tolist()\n",
        "\n",
        "    # Prepend number of vectors averaged\n",
        "    return avg_vector"
      ],
      "metadata": {
        "id": "XPrZuTlQs17k"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = \"Excel Files/Zang_Data.xlsx\"\n",
        "property = [\"Log VP\", \"MP\", \"BP\", \"LogBCF\", \"LogS\", \"LogP\"]\n",
        "\n",
        "output_dir = \"Descriptors Data\"\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "BHsvRkYJuwtx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tqdm.pandas()\n",
        "\n",
        "for prop in property:\n",
        "    df = pd.read_excel(input_file, sheet_name=prop)\n",
        "    df['Preferred_name'] = df['Preferred_name'].astype(str)\n",
        "\n",
        "    print(f\"\\nProcessing SMILES from sheet:{prop} .... \\n\")\n",
        "\n",
        "    df['mol'] = df['SMILES'].progress_apply(mol_from_smile)\n",
        "    df['Desc'] = df['mol'].progress_apply(compute_avg_weighted_path_vector)\n",
        "    df['AtomsC'] = df['mol'].progress_apply(count_atom_types)\n",
        "\n",
        "    desc_list = df['Desc'].tolist()\n",
        "    Desc_df = pd.DataFrame(desc_list)\n",
        "    Desc_df.columns = [f\"{prop}_{i}\" for i in range(Desc_df.shape[1])]\n",
        "    Desc_df.fillna(0, inplace=True)\n",
        "\n",
        "    output_file = os.path.join(output_dir, f\"{prop}_Desc_Paths.parquet\")\n",
        "    pd.concat([df.iloc[:, :9], Desc_df], axis=1).to_parquet(output_file, index=False)\n",
        "    print(f\"\\nThe process of sheet:{prop} is done! and the result is saved to the file {output_file}.\")\n",
        "\n",
        "    desc_list_atoms_count = df['AtomsC'].tolist()\n",
        "    Desc_Atoms_df = pd.DataFrame(desc_list_atoms_count)\n",
        "    Desc_Atoms_df.fillna(0, inplace=True)\n",
        "\n",
        "    output_file = os.path.join(output_dir, f\"{prop}_Desc_Atoms_Count.parquet\")\n",
        "    pd.concat([df.iloc[:, :9], Desc_Atoms_df], axis=1).to_parquet(output_file, index=False)\n",
        "    print(f\"The process of sheet:{prop} is done! and the result is saved to the file {output_file}.\")\n",
        "\n",
        "    Final_Desc_df = pd.concat([Desc_df, Desc_Atoms_df], axis=1)\n",
        "\n",
        "    output_file = os.path.join(output_dir, f\"{prop}_Desc_Full.parquet\")\n",
        "    pd.concat([df.iloc[:, :9], Final_Desc_df], axis=1).to_parquet(output_file, index=False)\n",
        "    print(f\"The process of sheet:{prop} is done! and the result is saved to the file {output_file}.\\n\")\n",
        "\n",
        "print(f'\\nAll sheets have been processed successfully!')"
      ],
      "metadata": {
        "id": "cPaZ6rE5vQ_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To inspect the values of some computed descriptors"
      ],
      "metadata": {
        "id": "OBrKc2o8yeOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "desc_data = pd.read_parquet('Descriptors Data/MP_Desc_Full.parquet')\n",
        "desc_data.head()"
      ],
      "metadata": {
        "id": "3BzmM8VLyfv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GhJz8O0_ypNk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}